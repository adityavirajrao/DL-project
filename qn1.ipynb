{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "#import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(folder)\n",
    "    # print(class_names)\n",
    "    class_index = 0\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            for filename in os.listdir(class_folder):\n",
    "                img_path = os.path.join(class_folder, filename)\n",
    "                # Read the image using OpenCV\n",
    "                image = cv2.imread(img_path)\n",
    "                # Resize the image if needed\n",
    "                # image = cv2.resize(image, (width, height))\n",
    "                if image is not None:\n",
    "                    images.append(image)\n",
    "                    labels.append(class_index)\n",
    "        class_index += 1\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 2000\n",
      "Test images: 500\n",
      "Valid images: 500\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = load_images_from_folder('task1/train')\n",
    "test_images, test_labels = load_images_from_folder('task1/test')\n",
    "valid_images, valid_labels = load_images_from_folder('task1/valid')\n",
    "\n",
    "print('Train images:', len(train_images))\n",
    "print('Test images:', len(test_images))\n",
    "print('Valid images:', len(valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class index to name\n",
    "# 0 - beetle\n",
    "# 1 - sloth\n",
    "# 2 - pencil pouch\n",
    "# 3 - xerox machine\n",
    "# 4 - vase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_images[0].shape)\n",
    "# print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "valid_images = valid_images / 255.0\n",
    "\n",
    "# print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_model.trainable = False\n",
    "# print(vgg_model.summary())\n",
    "inception_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "inception_model.trainable = False\n",
    "# print(inception_model.summary())\n",
    "\n",
    "flatten_layer = tf.keras.layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = tf.keras.models.Sequential([\n",
    "    vgg_model,\n",
    "    flatten_layer,\n",
    "    tf.keras.layers.Dense(100, activation='tanh'),\n",
    "    tf.keras.layers.Dense(50, activation='tanh'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model_inception = tf.keras.models.Sequential([\n",
    "    inception_model,\n",
    "    flatten_layer,\n",
    "    tf.keras.layers.Dense(100, activation='tanh'),\n",
    "    tf.keras.layers.Dense(50, activation='tanh'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_inception.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.8854 - accuracy: 0.7570 - val_loss: 0.4073 - val_accuracy: 0.8940\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 210s 3s/step - loss: 0.2351 - accuracy: 0.9450 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 203s 3s/step - loss: 0.1141 - accuracy: 0.9795 - val_loss: 0.2858 - val_accuracy: 0.9060\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 46s 713ms/step - loss: 0.3168 - accuracy: 0.9245 - val_loss: 0.1050 - val_accuracy: 0.9820\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 44s 696ms/step - loss: 0.0812 - accuracy: 0.9860 - val_loss: 0.0925 - val_accuracy: 0.9820\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 42s 672ms/step - loss: 0.0674 - accuracy: 0.9860 - val_loss: 0.0785 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x34e530710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg.fit(train_images, train_labels, epochs=3, validation_data=(valid_images, valid_labels))\n",
    "model_inception.fit(train_images, train_labels, epochs=3, validation_data=(valid_images, valid_labels))\n",
    "\n",
    "#as the validaition accuracy started to decrease after 3 epochs, we stop training the model to avoid overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 45s 3s/step - loss: 0.2355 - accuracy: 0.9260\n",
      "16/16 [==============================] - 9s 560ms/step - loss: 0.1066 - accuracy: 0.9720\n",
      "VGG test accuracy: 0.9259999990463257\n",
      "Inception test accuracy: 0.972000002861023\n"
     ]
    }
   ],
   "source": [
    "#getting the test accuracy\n",
    "vgg_test_loss, vgg_test_accuracy = model_vgg.evaluate(test_images, test_labels)\n",
    "inception_test_loss, inception_test_accuracy = model_inception.evaluate(test_images, test_labels)\n",
    "\n",
    "print('VGG test accuracy:', vgg_test_accuracy)\n",
    "print('Inception test accuracy:', inception_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 167s 3s/step\n",
      "16/16 [==============================] - 44s 3s/step\n",
      "63/63 [==============================] - 34s 526ms/step\n",
      "16/16 [==============================] - 8s 495ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on training and test data\n",
    "train_predictions_vgg = model_vgg.predict(train_images)\n",
    "test_predictions_vgg = model_vgg.predict(test_images)\n",
    "train_predictions_inception = model_inception.predict(train_images)\n",
    "test_predictions_inception = model_inception.predict(test_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_vgg = np.argmax(train_predictions_vgg, axis=1)\n",
    "test_predictions_vgg = np.argmax(test_predictions_vgg, axis=1)\n",
    "train_predictions_inception = np.argmax(train_predictions_inception, axis=1)\n",
    "test_predictions_inception = np.argmax(test_predictions_inception, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 41s 3s/step - loss: 0.2355 - accuracy: 0.9260\n",
      "16/16 [==============================] - 11s 686ms/step - loss: 0.1066 - accuracy: 0.9720\n",
      "63/63 [==============================] - 179s 3s/step - loss: 0.0932 - accuracy: 0.9860\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.0516 - accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "vgg_test_loss, vgg_test_accuracy = model_vgg.evaluate(test_images, test_labels)\n",
    "inception_test_loss, inception_test_accuracy = model_inception.evaluate(test_images, test_labels)\n",
    "vgg_train_loss, vgg_train_accuracy = model_vgg.evaluate(train_images, train_labels)\n",
    "inception_train_loss, inception_train_accuracy = model_inception.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_predictions_vgg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix for VGGNet\n",
      "[[396   0   3   1   0]\n",
      " [  0 390   1   1   8]\n",
      " [  4   0 393   0   3]\n",
      " [  1   1   0 394   4]\n",
      " [  0   0   0   1 399]]\n",
      "Accuracy for train data using VGGNet:  0.9860000014305115\n",
      "Test Confusion Matrix for VGGNet\n",
      "[[93  0  6  1  0]\n",
      " [ 0 89  0  3  8]\n",
      " [ 7  0 93  0  0]\n",
      " [ 1  0  3 94  2]\n",
      " [ 1  0  1  4 94]]\n",
      "Accuracy for test data using VGGNet:  0.9259999990463257\n",
      "Train Confusion Matrix for Inception\n",
      "[[398   0   0   2   0]\n",
      " [  0 397   0   0   3]\n",
      " [  5   0 390   2   3]\n",
      " [  0   0   0 399   1]\n",
      " [  0   0   0   2 398]]\n",
      "Accuracy for train data using Inception:  0.9909999966621399\n",
      "Test Confusion Matrix for Inception\n",
      "[[98  0  0  0  2]\n",
      " [ 0 98  0  0  2]\n",
      " [ 4  1 92  0  3]\n",
      " [ 0  0  0 99  1]\n",
      " [ 0  0  0  1 99]]\n",
      "Accuracy for test data using Inception:  0.972000002861023\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrices for training and test data\n",
    "train_confusion_matrix_vgg = confusion_matrix(train_labels, train_predictions_vgg)\n",
    "test_confusion_matrix_vgg = confusion_matrix(test_labels, test_predictions_vgg)\n",
    "\n",
    "# Calculate confusion matrices for training and test data\n",
    "train_confusion_matrix_inception = confusion_matrix(train_labels, train_predictions_inception)\n",
    "test_confusion_matrix_inception = confusion_matrix(test_labels, test_predictions_inception)\n",
    "\n",
    "print(\"Train Confusion Matrix for VGGNet\")\n",
    "print(train_confusion_matrix_vgg)\n",
    "print('Accuracy for train data using VGGNet: ',vgg_train_accuracy)\n",
    "print(\"Test Confusion Matrix for VGGNet\")\n",
    "print(test_confusion_matrix_vgg)\n",
    "print('Accuracy for test data using VGGNet: ',vgg_test_accuracy)\n",
    "\n",
    "print(\"Train Confusion Matrix for Inception\")\n",
    "print(train_confusion_matrix_inception)\n",
    "print('Accuracy for train data using Inception: ',inception_train_accuracy)\n",
    "print(\"Test Confusion Matrix for Inception\")\n",
    "print(test_confusion_matrix_inception)\n",
    "print('Accuracy for test data using Inception: ',inception_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
