{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'glove.6B/glove.6B.50d.txt'\n",
    "input_dim = 50\n",
    "\n",
    "# Load datasets from CSV files\n",
    "train_dataset = load_dataset('csv', data_files='team16_ta_train.csv', split='train')\n",
    "validation_dataset = load_dataset('csv', data_files='team16_ta_valid.csv', split='train')\n",
    "test_dataset = load_dataset('csv', data_files='team16_ta_test.csv', split='train')\n",
    "\n",
    "# Create a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    '<pad>': np.zeros(input_dim),\n",
    "    '<sos>': np.random.normal(size=(input_dim,)),\n",
    "    '<eos>': np.random.normal(size=(input_dim,)),\n",
    "    '<unk>': np.random.normal(size=(input_dim,))\n",
    "}\n",
    "\n",
    "glove_embeddings.update(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text_list):\n",
    "    if type(text_list) is str:\n",
    "        text_list = [text_list]\n",
    "    batch_tokens = [word_tokenize(text) for text in text_list]\n",
    "    max_length = max([len(token_list) for token_list in batch_tokens])\n",
    "    for token_list in batch_tokens:\n",
    "        token_list.extend(['<pad>'] * (max_length - len(token_list)))\n",
    "    return batch_tokens\n",
    "\n",
    "def embedding_en(token_list):\n",
    "    def compute_embedding(tokens):\n",
    "        vectors = [glove_embeddings.get(token, glove_embeddings['<unk>']) for token in tokens]\n",
    "        return torch.tensor(vectors, dtype=torch.float32)\n",
    "\n",
    "    if not isinstance(token_list[0], list):\n",
    "        token_list = [token_list]\n",
    "    batch_tensors = [compute_embedding(tokens) for tokens in token_list]\n",
    "    return torch.stack(batch_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samk1\\Conda\\miniconda3\\envs\\rosemilk\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
    "model = AlbertModel.from_pretrained('ai4bharat/indic-bert')\n",
    "\n",
    "def tokenize_ta(text):\n",
    "    return tokenizer(text, padding=True, return_tensors='pt')\n",
    "\n",
    "def embedding_ta(tokens:dict|torch.Tensor, model=model):   \n",
    "    with torch.no_grad():\n",
    "        if isinstance(tokens, torch.Tensor):\n",
    "            output = model(tokens)\n",
    "        else:\n",
    "            output = model(**tokens)\n",
    "\n",
    "    return output.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vocabolary for Target Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:38<00:00, 1825.75it/s]\n",
      "8074it [00:00, 1345924.66it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_vocab_ta():\n",
    "    temp = {0: 3}\n",
    "    for sentence in tqdm(dataset['train']['target']):\n",
    "        for token in tokenize_ta(sentence)['input_ids'][0]:\n",
    "            if temp.get(token.item()) is None:\n",
    "                temp[token.item()] = 1\n",
    "            else:\n",
    "                temp[token.item()] = temp[token.item()] + 1\n",
    "    \n",
    "    vocab = set()\n",
    "    for tk in temp.keys():\n",
    "        if temp[tk] > 1:\n",
    "            vocab.add(tk)\n",
    "            \n",
    "    return torch.tensor(np.sort(list(vocab)))\n",
    "\n",
    "vocab_ta = build_vocab_ta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8074it [00:00, 532398.61it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_ta = dict()\n",
    "for id, token in tqdm(enumerate(vocab_ta)):\n",
    "    token_ta[token.item()] = id\n",
    "\n",
    "def token_to_id(target):\n",
    "    if target.dim() == 0:\n",
    "        return torch.tensor(token_ta.get(target.item(), 2))\n",
    "    else:\n",
    "        return torch.stack([token_to_id(tgt) for tgt in target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8073/8073 [03:31<00:00, 38.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_map(vocab):\n",
    "    vocab_map = dict()\n",
    "    model_input = {\n",
    "        'token_type_ids':   torch.tensor(0).reshape(1,1),\n",
    "        'attention_mask':   torch.tensor(1).reshape(1,1)\n",
    "    }\n",
    "    for token in tqdm(vocab):\n",
    "        model_input['input_ids'] = torch.tensor(token.item()).reshape(1,1)\n",
    "        with torch.no_grad():\n",
    "            vocab_map[token.item()] = model(**model_input).last_hidden_state\n",
    "    \n",
    "    return vocab_map\n",
    "\n",
    "# dict with each token as key and respective embedding as value\n",
    "map_ta = build_map(vocab_ta)\n",
    "map_ta[0] = torch.zeros(1, 1, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, dtype=torch.float32)\n",
    "\n",
    "    # input_seq : source sequence embeddings => (N, seq_len, em_size) / (seq_len, em_size)\n",
    "    def forward(self, input_seq):\n",
    "        output, curr_state = self.rnn(input_seq)\n",
    "        return curr_state\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, dtype=torch.float32)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim, dtype=torch.float32)\n",
    "    \n",
    "    # y : [mostly] prev. (expected) word embedding => (N, em_size) / (1, em_size)\n",
    "    def forward(self, y, prev_state):\n",
    "        output, curr_state = self.rnn(y, prev_state)\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, curr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, src_em_dim, hidden_dim, tgt_em_dim, tgt_dim):\n",
    "        super().__init__()\n",
    "        self.src_em_dim = src_em_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tgt_em_dim = tgt_em_dim\n",
    "        self.tgt_dim = tgt_dim\n",
    "        self.encoder = Encoder(src_em_dim, hidden_dim)\n",
    "        self.decoder = Decoder(tgt_em_dim, hidden_dim, tgt_dim)\n",
    "\n",
    "    # source : tensor of embeddings of tokens\n",
    "    # target : tensor of tokens only => (N, seq_len)\n",
    "    def forward(self, source, target=None):\n",
    "        batch_size = source.shape[0]\n",
    "        target_len = 1000 if target is None else target.shape[1]\n",
    "        \n",
    "        last_encoder_state = self.encoder(source)\n",
    "\n",
    "        outputs = []\n",
    "        prev_state = last_encoder_state\n",
    "\n",
    "        # should be (N, 1, em_size)\n",
    "        decoder_input = torch.tile(map_ta[2], (batch_size, 1, 1))\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            decoder_output, state = self.decoder(decoder_input, prev_state)\n",
    "            outputs.append(decoder_output)\n",
    "            prev_state = state\n",
    "\n",
    "            if self.training:\n",
    "                temp1 = [map_ta.get(tk.item(), map_ta[2]) for tk in target[:, t]]\n",
    "                decoder_input = torch.concat(temp1)\n",
    "            else:\n",
    "                decoder_input = torch.concat([map_ta.get(vocab_ta[torch.argmax(y)].item(), map_ta[2]) for y in decoder_output])\n",
    "            \n",
    "        return torch.concat(outputs, dim=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "en_vocab_size = 0 # not neccesary since we are not constructing any vocabolary for english and it is not needed\n",
    "en_embedding_size = input_dim\n",
    "ta_vocab_size = len(vocab_ta)\n",
    "ta_embedding_size = 768\n",
    "\n",
    "hidden_dim = en_embedding_size * 2\n",
    "\n",
    "machine = Seq2SeqModel(en_embedding_size, hidden_dim, ta_embedding_size, ta_vocab_size)\n",
    "\n",
    "machine.encoder.to(device)\n",
    "machine.decoder.to(device)\n",
    "machine.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(machine.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['source', 'target'])\n",
    "validation_dataset.set_format(type='torch', columns=['source', 'target'])\n",
    "test_dataset.set_format(type='torch', columns=['source', 'target'])\n",
    "\n",
    "def collate_fn(example_list: list):\n",
    "    source_list = [example['source'] for example in example_list]\n",
    "    target_list = [example['target'] for example in example_list]\n",
    "\n",
    "    source_tensor = embedding_en(tokenize_en(source_list))\n",
    "    target_tensor = tokenize_ta(target_list)['input_ids']\n",
    "\n",
    "    return source_tensor, target_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [34:03<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] ----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_iterator = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    for source, target in tqdm(train_iterator):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = machine(source, target)\n",
    "        \n",
    "        target_one_hot = nn.functional.one_hot(token_to_id(target[:, 1:]), num_classes=machine.tgt_dim).float()\n",
    "        loss = criterion(outputs, target_one_hot)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}] ----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentences(outputs): \n",
    "\n",
    "    def decode_sentence(Y): # Y is 2D tensor => (seq_len, vocab_size)\n",
    "        tokens = []\n",
    "        for y in Y:\n",
    "            token = vocab_ta[torch.argmax(y)].item()\n",
    "            if token == 0:\n",
    "                break\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "            \n",
    "        return tokenizer.decode(tokens)\n",
    "\n",
    "    if len(outputs.shape) == 2:   \n",
    "        outputs = outputs.unsqueeze(dim=0)\n",
    "    \n",
    "    return [decode_sentence(Y) for Y in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('எனக்கு ஒன்றும் தோன்ற வில்லை.', ['கக'])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 5\n",
    "\n",
    "en_sentence = embedding_en(tokenize_en(dataset['train']['source'][idx]))\n",
    "ta_sentence = dataset['train']['target'][idx]\n",
    "\n",
    "machine.eval()\n",
    "outputs = machine(en_sentence)\n",
    "\n",
    "ta_sentence, decode_sentences(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosemilk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
